{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from threading import Thread\n",
    "from scipy import signal\n",
    "import soundfile as sf\n",
    "import os\n",
    "import sys\n",
    "import librosa\n",
    "import sys\n",
    "import mido\n",
    "import pyaudio as pa\n",
    "path = os.getcwd()\n",
    "#!{sys.executable} -m pip install --user pyrubberband\n",
    "import pyrubberband as pyrb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Clase abstracta Instrument para centralizar el comportamiento\n",
    "class Instrument:\n",
    "    \n",
    "    # Frecuencia fundamental de cada nota\n",
    "    notes = {'A' : 27.5, 'A#' : 29.0, 'B' : 30.87, 'Bb' : 29.135, 'C' : 16.35, 'C#' : 17.32, 'D' : 18.35, 'D#' : 19.0, 'E' : 20.6, 'Eb' : 19.445, 'F' : 21.83, 'F#' : 23.12 ,'G' : 24.5, 'G#' : 25.96}\n",
    "\n",
    "    # Conversiones de hexa a nota + octava.\n",
    "    df = pd.read_csv('Notes.csv').set_index('Num')\n",
    "    \n",
    "    # Carga de archivo MIDI\n",
    "    def load(self, midi): \n",
    "        self.midi, point = midi, 0\n",
    "        self.tempos = np.array([[0], [120]])\n",
    "        \n",
    "        # Genera vector de tempos para cada momento de la canción\n",
    "        for ev in self.midi.tracks[0]:\n",
    "            point += ev.time\n",
    "            if ev.is_meta and ev.type == 'set_tempo':\n",
    "                if point == 0: self.tempos = np.array([[point], [ev.tempo]])\n",
    "                else: self.tempos = np.append(self.tempos, [[point], [ev.tempo]], axis = 1)\n",
    "\n",
    "        # Genera vector de tiempo/tick para cada momento de la canción\n",
    "        self.time_steps = self.tempos[1] / (1e6 * self.midi.ticks_per_beat)\n",
    "    \n",
    "    # Devuelve el tiempo/tick para cierto punto de la canción\n",
    "    def current_timestep(self, point):\n",
    "        return self.time_steps[self.tempos[0] <= point][-1]\n",
    "\n",
    "    # Sintetiza el track elegido del MIDI previamente cargado.\n",
    "    # add: Si es True, entonces no borra los datos anterior, sino que los superpone.\n",
    "    # nochannels: Qué canales no cargar.\n",
    "    # lowtone: Cuántos armónicos bajarle a las notas.\n",
    "    # Los parámetros propios de cada instrumento se deben agregar en sus respectivos constructores\n",
    "    def synthesize(self, track : int, fs : float, add = False, nochannels = (), lowtone = 0, **kwargs):\n",
    "        self.track = self.midi.tracks[track]\n",
    "        self.fs = fs\n",
    "\n",
    "        if not hasattr(self, 'sound'): self.sound = np.zeros(int(np.ceil(self.fs * self.midi.length)))\n",
    "        elif not add:\n",
    "            self.sound = self.sound[ : int(np.ceil(self.fs * self.midi.length))]\n",
    "            self.sound[:] = 0\n",
    "            \n",
    "        point = real_time = 0\n",
    "        self.used_off = []\n",
    "        \n",
    "        # Itera por cada evento en el track\n",
    "        for i, ev in enumerate(self.track):\n",
    "\n",
    "            # Carga los valores de tiempo (real y ticks)\n",
    "            real_time += ev.time * self.current_timestep(point)\n",
    "            point += ev.time\n",
    "            \n",
    "            # Si el evento es apto para ser cargado como nota...\n",
    "            if not ev.is_meta and ev.type == 'note_on' and not ev.channel in nochannels and not i in self.used_off:\n",
    "                \n",
    "                # Obtiene información de la nota (frecuencia + octava)\n",
    "                info = self.df.loc[ev.note]\n",
    "                fnote, octave = self.notes[info['Note']], info['Octave']\n",
    "            \n",
    "                # Busca cuándo termina la nota y obtiene su duración\n",
    "                d, v = self._find_off(ev.note, i, ev.channel)\n",
    "                duration = d * self.current_timestep(point) * 1.5\n",
    "                \n",
    "                # Agrega la nota al vector de sonido\n",
    "                if duration: self._add_note(fnote, octave, duration, max(v, ev.velocity), real_time, lowtone, **kwargs)\n",
    "    \n",
    "    # Agrega una nota al vector de sonido\n",
    "    # fnote: Frecuencia\n",
    "    # octave: Octava\n",
    "    # duration: Duración\n",
    "    # velocity: Intensidad\n",
    "    # lowtone: Cuántos armónicos bajarle a las notas.\n",
    "    def _add_note(self, fnote, octave, duration, velocity, real_time, lowtone, **kwargs):\n",
    "        \n",
    "        # Genera la nota y normaliza su amplitud\n",
    "        nt = self._gen_note(freq = fnote * 2**max(0, octave-lowtone), dur = duration, **kwargs)\n",
    "        if np.count_nonzero(nt):\n",
    "            nt *= velocity / np.abs(nt).max() * octave\n",
    "        \n",
    "            # Busca el índice en el que empieza la nota\n",
    "            idx = int(np.round((self.fs * real_time), 0))\n",
    "\n",
    "            # Agrega puntos en caso de sobrar por redondeos\n",
    "            if idx + nt.size > self.sound.size:\n",
    "                self.sound = np.append(self.sound, np.zeros(idx + nt.size - self.sound.size))\n",
    "                    \n",
    "            # Agrega la nota\n",
    "            self.sound[idx : idx + nt.size] += nt\n",
    "    \n",
    "    # Busca cuándo termina una nota\n",
    "    # note: La nota que debe terminar\n",
    "    # idx: Índice a partir del cual puede estar el evento de off\n",
    "    # channel: Canal al cual corresponde la nota\n",
    "    def _find_off(self, note, idx, channel):\n",
    "        tot = 0\n",
    "\n",
    "        # Itera por cada evento, sumando los tiempos\n",
    "        for i, ev in enumerate(self.track[idx + 1:]):\n",
    "            tot += ev.time\n",
    "            \n",
    "            # Si encontró el correcto, devuelve la duración y la intensidad\n",
    "            if not ev.is_meta and ev.type in ['note_on', 'note_off'] and ev.note == note and ev.channel == channel:\n",
    "                self.used_off.append(i + idx + 1)\n",
    "                return tot, ev.velocity\n",
    "\n",
    "        return 0, 0\n",
    "\n",
    "    # Las implementaciones de _gen_note tienen que tener esta forma siempre, y en **kwargs\n",
    "    # se reciben los parámetros propios de cada instrumento.\n",
    "    def _gen_note(self, freq, dur, **kwargs):\n",
    "        raise Exception('No note generator: _gen_note() must be overwritten for each class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase abstracta SampleBasedInstrument para los instrumentos sintetizados por muestras.\n",
    "class SampleBasedInstrument(Instrument):\n",
    "    \n",
    "    # Constructor. Tira error si se intenta instanciar.\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        raise Exception('Cannot instantiate abstract class SampleBasedInstrument')\n",
    "        \n",
    "    #Genera un diccionario para asociar cada una de las muestras con su correspondiente frecuencia. (Ej samples_dic[0]=\"F6\").\n",
    "    def generate_samples_dic(self):\n",
    "        self.samples_dic={}\n",
    "        for sample in os.listdir(self.samples_location):\n",
    "            instr_note=sample.split(\".\")\n",
    "            self.samples_dic[sample]=self.frec_dic[instr_note[-2]] #Notamos que el value sale del diccionario de frecuencias creado al principio.\n",
    "        #print(self.samples_dic)\n",
    "        \n",
    "    #Crea un diccionario con las distintas notas y sus correspondientes frecuencias\n",
    "    def create_frec_index(self):\n",
    "        self.frec_dic={}\n",
    "        notes = [\"A0\", \"Bb0\", \"B0\",\"C1\", \"Db1\", \"D1\", \"Eb1\", \"E1\", \"F1\", \"Gb1\", \"G1\", \"Ab1\", \"A1\", \"Bb1\", \"B1\",\n",
    "                   \"C2\", \"Db2\", \"D2\", \"Eb2\", \"E2\", \"F2\", \"Gb2\", \"G2\", \"Ab2\", \"A2\", \"Bb2\", \"B2\",\n",
    "                   \"C3\", \"Db3\", \"D3\", \"Eb3\", \"E3\", \"F3\", \"Gb3\", \"G3\", \"Ab3\", \"A3\", \"Bb3\", \"B3\",\n",
    "                   \"C4\", \"Db4\", \"D4\", \"Eb4\", \"E4\", \"F4\", \"Gb4\", \"G4\", \"Ab4\", \"A4\", \"Bb4\", \"B4\",\n",
    "                   \"C5\", \"Db5\", \"D5\", \"Eb5\", \"E5\", \"F5\", \"Gb5\", \"G5\", \"Ab5\", \"A5\", \"Bb5\", \"B5\",\n",
    "                   \"C6\", \"Db6\", \"D6\", \"Eb6\", \"E6\", \"F6\", \"Gb6\", \"G6\", \"Ab6\", \"A6\", \"Bb6\", \"B6\",\n",
    "                   \"C7\", \"Db7\", \"D7\", \"Eb7\", \"E7\", \"F7\", \"Gb7\", \"G7\", \"Ab7\", \"A7\", \"Bb7\", \"B7\",\"C8\"]\n",
    "        i=0\n",
    "        for note_ in notes:\n",
    "            frec=round(440/32*(2**(((21+i)-9)/12)), 3)\n",
    "            self.frec_dic[note_]=frec\n",
    "            i+=1\n",
    "        #print(self.frec_dic)\n",
    "\n",
    "    #Busca la muestra que más se parece en frecuencia a la frecuencia de la nota.\n",
    "    def find_closest_note(self, freq):\n",
    "        #Devuelve la muestra correspondiente en forma de string (es el nombre del archivo sin la terminación)\n",
    "        #Búsqueda del key tal que su value minimice una condición tomada de \n",
    "        #https://stackoverflow.com/questions/3282823/get-the-key-corresponding-to-the-minimum-value-within-a-dictionary\n",
    "        closest_note_=min(self.samples_dic, key=lambda x: abs(self.samples_dic[x]-freq))\n",
    "        return closest_note_\n",
    "\n",
    "    #Recupera el código MIDI correspondiente a una frecuencia\n",
    "    def get_midi_note(self, frec):\n",
    "        #return 12*np.log2(frec/440)+69\n",
    "        return 12 * np.log2(frec * 32 / 440) + 9\n",
    "        \n",
    "        \n",
    "    #Se busca estirar o comprimir la señal en tiempo sin afectar el tono o pitch\n",
    "    #Estira o comprime la señal sample_data en un factor time_scaling_factor\n",
    "    #Para pasar al dominio de la frecuencia se realiza la STFT, usando una ventana de Hann\n",
    "    #La STFT se implementa con la librería librosa\n",
    "    def time_scale(self, sample_data, time_scaling_factor):\n",
    "        #stft(y, n_fft=2048, hop_length=None, win_length=None, window='hann', center=True, dtype=np.complex64, pad_mode='reflect')\n",
    "        #Returns D such that\n",
    "        #np.abs(D[f, t]) is the magnitude of frequency bin f at frame t, and\n",
    "        #np.angle(D[f, t]) is the phase of frequency bin f at frame t.\n",
    "        #D es una matriz de tamaño (1+n_fft/2)*t\n",
    "\n",
    "        #Computo STFT\n",
    "        FFT_window_size=2048\n",
    "        frame_size=2048\n",
    "        hop_size=frame_size/4\n",
    "        STFT=librosa.core.stft(sample_data,n_fft=2048).transpose()\n",
    "        #Filas= STFT.shape[0] #cantidad de instantes\n",
    "        #Columnas= STFT.shape[1] #cantidad de bines/2+1 por simetría: 1025\n",
    "\n",
    "        scaled_time_axis=np.arange(0,STFT.shape[0],time_scaling_factor) #Nuevo arreglo de tiempos, original tomado cada time_scaling_factor\n",
    "        time_scaled_STFT=np.zeros((len(scaled_time_axis),STFT.shape[1]), dtype=np.complex_) #Arreglo de len(time_scaled_data) elementos, donde cada elemento es un arreglo de tamaño STFT_columns, y cada elemento de este último arreglo es un número complejo\n",
    "        phase=np.angle(STFT[0]) #fase espectral de cada bin (valores entre -pi y pi)\n",
    "        delta_t=hop_size/FFT_window_size\n",
    "        expected_phase=2 * np.pi * delta_t * np.arange(0, STFT.shape[1])\n",
    "        #expected_phase=(2 * np.pi * hop_size * np.arange(0, STFT.shape[1]))/FFT_window_size #valores entre cero y (2*pi)*(1/4)*1025 (unwrapped)\n",
    "        STFT=np.concatenate((STFT,np.zeros((1,STFT.shape[1]))), axis=0)\n",
    "\n",
    "        #Implementación del algoritmo en sí. Se realiza la correción de fase para formar la matriz espectral escalada en tiempo.\n",
    "        for i, time_data in enumerate(scaled_time_axis):\n",
    "            left_frame=int(np.floor(time_data))\n",
    "            right_frame=left_frame+1\n",
    "            weight=time_data-np.floor(time_data) #Ver *\n",
    "            current_frame=STFT[[left_frame,right_frame],:] #Los datos de mi stft que corresponden al frame temporal que estoy analizando\n",
    "            local_magnitude=(1-weight)*np.absolute(current_frame[0,:])+weight*np.absolute(current_frame[1,:]) #Se computa la magnitud de la ventana temporal con peso\n",
    "            \n",
    "            #Hay que calcular la fase predicha con la frecuencia de bin sin wrapping, \n",
    "            #luego hallar el error de fase entre ventanas, hacerle un wrapping para que esté entre -pi y pi, y\n",
    "            #luego estimar la fase real\n",
    "            predicted_phase=np.angle(current_frame[0,:])+expected_phase\n",
    "            phase_error=np.angle(current_frame[1,:])-predicted_phase\n",
    "            wrap_factor=np.floor(phase_error/(2*np.pi)) #cuántos múltiplos de 2pi hay que restar\n",
    "            phase_error_wrapped=phase_error-2*np.pi*wrap_factor\n",
    "            time_scaled_STFT[i,:]=local_magnitude*np.exp(phase*1j)\n",
    "            phase+=phase_error_wrapped+expected_phase\n",
    "            \n",
    "        return librosa.core.istft(time_scaled_STFT.transpose())\n",
    "        #* Los tiempos son enteros, t=1,2,... Pero puede ser que por mi factor de escalamiento, los tenga que computar en tiempos no enteros, ej: t=1.7\n",
    "        #Entonces, tomo mis ventanas left=1 y right=2, y tomo weight=0.7. Al considerar magnitud, la de t=2 tendrá más peso\n",
    "        #Luego, mag=0.3*mag(t1)+0.7*mag(t2)\n",
    "        \n",
    "    # Método que se debe sobreescribir para cada clase de instrumento. Genera una nota.\n",
    "    # freq: Frecuencia de la nota\n",
    "    # dur: Duración de la nota\n",
    "    # stretch_factor: Límite inferior de frecuencia para lingering\n",
    "    # b: Parámetro propio de cada instrumento\n",
    "    # La frecuencia de sampleo fs es propia de la instancia, y se obtiene con self.fs   \n",
    "\n",
    "    def pitch_shift(self, sample_data, samplerate, shift, time_scaling_factor):\n",
    "        #El cambio de tonos se hace primero haciendo un cambio en el tiempo con la función time_scaling\n",
    "        #Y luego resampleando a mayor velocidad para recuperar la longitud original del tiempo\n",
    "        FFT_size=2048\n",
    "        pitch_shift_factor=2**(1.0*shift/12.0) #Recordar que el shift se consiguió en semitonos       \n",
    "        total_scaling_factor=len(sample_data)/(len(sample_data)*pitch_shift_factor)*time_scaling_factor\n",
    "        #total_scaling_factor=len(sample_data)/(len(sample_data)*pitch_shift_factor+FFT_size)*time_scaling_factor #Cambio en el tiempo por cambio de tono + duración\n",
    "        #total_scaling_factor=pitch_shift_factor*time_scaling_factor\n",
    "        time_scaled_signal=self.time_scale(sample_data,total_scaling_factor)\n",
    "        #print('factor:')\n",
    "        #print(pitch_shift_factor)\n",
    "        #print('Total scaling factor:')\n",
    "        #print(total_scaling_factor)\n",
    "        \n",
    "        #Ahora se debe resamplear la señal para acomodar la longitud a la buscada\n",
    "        #pitch_shifted_signal=signal.resample(x=np.floor(time_scaled_signal[FFT_size:]), num=pitch_shift_factor)\n",
    "        #pitch_shifted_signal=self.resample(time_scaled_signal[FFT_size:],pitch_shift_factor)\n",
    "        pitch_shifted_signal=self.resample(time_scaled_signal,pitch_shift_factor)\n",
    "        return pitch_shifted_signal.astype(sample_data.dtype)\n",
    "    \n",
    "    def resample(self,input_,factor):\n",
    "        #Primero se crea el nuevo arreglo espaciado según el factor de resampleo, y luego se copian los valores \n",
    "        #del arreglo original que correspondan. La correción de new_times tiene que ver con cómo funciona astype(int) en numpy arrays\n",
    "        new_times_temp=np.round(np.arange(0,len(input_),factor))\n",
    "        new_times=new_times_temp[new_times_temp<len(input_)].astype(int)\n",
    "        resampled_input=input_[new_times.astype(int)]\n",
    "        return resampled_input\n",
    "        #output_length=int((len(input_)-1)/factor)\n",
    "        #output=np.zeros(output_length)\n",
    "        #for i in range(output_length-1):\n",
    "        #    x = float(i*factor)\n",
    "        #    ix = np.floor(x)\n",
    "        #    dx = x - ix\n",
    "        #    output[i] = input_[ix]*(1.0 - dx) + input_[ix+1]*dx\n",
    "        #return output       \n",
    "    \n",
    "    def _gen_note(self, freq, dur, **kwargs):\n",
    "        # Crea vector resultante con la duración correspondiente\n",
    "        samples = np.zeros(int(np.round(self.fs * dur, 0)))\n",
    "        #print(freq)\n",
    "\n",
    "        #Busco la muestra que más se parezca en frecuencia a la frecuencia de la nota que se quiere sintetizar.\n",
    "        closest_note=self.find_closest_note(freq)\n",
    "        #print(closest_note)\n",
    "\n",
    "        #Recupero los códigos midi de la frecuencia a sintetizar y de la más cercana que hay en mis muestras\n",
    "        MIDI_note=self.get_midi_note(freq)\n",
    "        MIDI_closest_note=self.get_midi_note(self.samples_dic[closest_note])\n",
    "        #print('MIDI note')\n",
    "        #print(MIDI_note)\n",
    "        #print('MIDI closest')\n",
    "        #print(MIDI_closest_note)\n",
    "\n",
    "        #A partir de esos códigos, puede ver cuántos debo correr la nota de mi muestra para que sea igual a la que tengo que sintetizar.\n",
    "        #Se hace en MIDI ya que ésta es la unidad de tonos\n",
    "        #shift es cantidad de semitonos\n",
    "        shift=MIDI_note-round(MIDI_closest_note)\n",
    "        #print(shift)\n",
    "        \n",
    "        #Se recupera la información de la muestra que más se acerca a la nota deseada y sobre la que se trabajará.\n",
    "        #sample_data es un array 1*number_of_samples que tiene el valor de amplitud de cada una de las samples del archivo .wav\n",
    "        #samplerate es la frecuencia de muestreo del archivo .wav\n",
    "        sample_data, samplerate=sf.read(self.samples_location+closest_note) #Notamos que el argumento es ahora el path completo a la muestra.\n",
    "        #Se recupera la duración en samples de la nota a sintetizar.\n",
    "        note_dur_in_samples=int(round(dur*self.fs))\n",
    "\n",
    "        #Puede ocurrir que la nota buscada esté contenida en mis muestras, de donde shift=0 y no se requiere procesamiento en tono alguno.\n",
    "        #No obstante, puede ser que la duración de la muestra difiera de la de la nota buscada, de donde se precisa alargar o comprimir la muestra.\n",
    "        #Como simplemente samplear a mayor o menor velocidad modifica la parte espectral de la señal (pitch), indefectiblemente se debe buscar otra manera\n",
    "        #Se utiliza un algoritmo llamado Phase Vocoder. Primero se hace un cambio en frecuencia y luego se introduce el cambio temporal en frecuencia\n",
    "        #Manteniendo el tono, y luego haciendo la transformada inversa para recuperar la señal en el tiempo\n",
    "        \n",
    "        if int(shift)==0:\n",
    "            if(dur==0.0):\n",
    "                return samples\n",
    "            else:\n",
    "                time_scaling_factor=len(sample_data)/note_dur_in_samples #En cuántos samples se debe alargar o comprimir mi muestra. Si es mayor a 1, se comprime, menor a 1 se alarga\n",
    "                time_scaled_note=self.time_scale(sample_data, time_scaling_factor)\n",
    "                #time_scaled_note=pyrb.time_stretch(sample_data,sr=samplerate,rate=time_scaling_factor)\n",
    "                #if(len(time_scaled_note)>note_dur_in_samples):\n",
    "                #    k=len(time_scaled_note)-note_dur_in_samples\n",
    "                #    while(k>0):\n",
    "                #        time_scaled_note=np.delete(time_scaled_note,len(time_scaled_note)-1)\n",
    "                #        k=k-1\n",
    "                #elif(len(time_scaled_note)<note_dur_in_samples):\n",
    "                #    k=note_dur_in_samples-len(time_scaled_note)\n",
    "                #    while(k>0):\n",
    "                #        time_scaled_note=np.insert(time_scaled_note,len(time_scaled_note),0)\n",
    "                #        k=k-1\n",
    "                #print(\"\\n\")\n",
    "                return time_scaled_note\n",
    "\n",
    "        else:\n",
    "            if(dur==0.0):\n",
    "                return samples\n",
    "            else:\n",
    "                #Hay que escalar en tiempo y en frecuencia\n",
    "                time_scaling_factor_=len(sample_data)/note_dur_in_samples\n",
    "                pitch_shifted_note=self.pitch_shift(sample_data,samplerate,shift,time_scaling_factor_)\n",
    "                #factor=2**(1.0*shift/12.0)\n",
    "                #pitch_shifted_note=pyrb.pitch_shift(y=sample_data,sr=samplerate,n_steps=factor)\n",
    "                #time_scaling_factor_=len(pitch_shifted_note)/note_dur_in_samples\n",
    "                #time_shifted_note=pyrb.time_stretch(y=pitch_shifted_note,sr=samplerate,rate=time_scaling_factor_)\n",
    "                #print('longitud de la señal')\n",
    "                #print(len(pitch_shifted_note))\n",
    "                #if(len(pitch_shifted_note)>note_dur_in_samples):\n",
    "                #    k=len(pitch_shifted_note)-note_dur_in_samples\n",
    "                #    while(k>0):\n",
    "                #        pitch_shifted_note=np.delete(pitch_shifted_note,len(pitch_shifted_note)-1)\n",
    "                #        k=k-1\n",
    "                #elif(len(pitch_shifted_note)<note_dur_in_samples):\n",
    "                #    k=note_dur_in_samples-len(pitch_shifted_note)\n",
    "                #    while(k>0):\n",
    "                #        pitch_shifted_note=np.insert(pitch_shifted_note,len(pitch_shifted_note),0)\n",
    "                #        k=k-1\n",
    "                #print(\"\\n\")\n",
    "                return pitch_shifted_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleBasedPiano(SampleBasedInstrument):\n",
    "   \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.instrument='Piano'\n",
    "        #print(self.instrument)\n",
    "        self.samples_location=path + '/Note_samples/' + self.instrument + '/'\n",
    "        #print(self.samples_location)\n",
    "        self.create_frec_index() #Crea índice para luego generar el diccionario con las muestras (Quizá se podría usar directamente el notes.csv)\n",
    "        self.generate_samples_dic()  # Crea el diccionario con las muestras \n",
    "    \n",
    "    def _gen_note(self, freq, dur, **kwargs):\n",
    "        return super()._gen_note(freq = freq, dur = dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleBasedGuitar(SampleBasedInstrument):\n",
    "   \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.instrument='AcousticGuitar'\n",
    "        #print(self.instrument)\n",
    "        self.samples_location=path + '/Note_samples/' + self.instrument + '/'\n",
    "        #print(self.samples_location)\n",
    "        self.create_frec_index() #Crea índice para luego generar el diccionario con las muestras (Quizá se podría usar directamente el notes.csv)\n",
    "        self.generate_samples_dic()  # Crea el diccionario con las muestras \n",
    "    \n",
    "    def _gen_note(self, freq, dur, **kwargs):\n",
    "        return super()._gen_note(freq = freq, dur = dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleBasedBanjo(SampleBasedInstrument):\n",
    "   \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.instrument='Banjo'\n",
    "        #print(self.instrument)\n",
    "        self.samples_location=path + '/Note_samples/' + self.instrument + '/'\n",
    "        #print(self.samples_location)\n",
    "        self.create_frec_index() #Crea índice para luego generar el diccionario con las muestras (Quizá se podría usar directamente el notes.csv)\n",
    "        self.generate_samples_dic()  # Crea el diccionario con las muestras \n",
    "    \n",
    "    def _gen_note(self, freq, dur, **kwargs):\n",
    "        return super()._gen_note(freq = freq, dur = dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleBasedElectricBass(SampleBasedInstrument):\n",
    "   \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.instrument='ElectricBass'\n",
    "        #print(self.instrument)\n",
    "        self.samples_location=path + '/Note_samples/' + self.instrument + '/'\n",
    "        #print(self.samples_location)\n",
    "        self.create_frec_index() #Crea índice para luego generar el diccionario con las muestras (Quizá se podría usar directamente el notes.csv)\n",
    "        self.generate_samples_dic()  # Crea el diccionario con las muestras \n",
    "    \n",
    "    def _gen_note(self, freq, dur, **kwargs):\n",
    "        return super()._gen_note(freq = freq, dur = dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleBasedSaxophone(SampleBasedInstrument):\n",
    "   \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.instrument='Saxophone'\n",
    "        #print(self.instrument)\n",
    "        self.samples_location=path + '/Note_samples/' + self.instrument + '/'\n",
    "        #print(self.samples_location)\n",
    "        self.create_frec_index() #Crea índice para luego generar el diccionario con las muestras (Quizá se podría usar directamente el notes.csv)\n",
    "        self.generate_samples_dic()  # Crea el diccionario con las muestras \n",
    "    \n",
    "    def _gen_note(self, freq, dur, **kwargs):\n",
    "        return super()._gen_note(freq = freq, dur = dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleBasedBassoon(SampleBasedInstrument):\n",
    "   \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.instrument='Bassoon'\n",
    "        #print(self.instrument)\n",
    "        self.samples_location=path + '/Note_samples/' + self.instrument + '/'\n",
    "        #print(self.samples_location)\n",
    "        self.create_frec_index() #Crea índice para luego generar el diccionario con las muestras (Quizá se podría usar directamente el notes.csv)\n",
    "        self.generate_samples_dic()  # Crea el diccionario con las muestras \n",
    "    \n",
    "    def _gen_note(self, freq, dur, **kwargs):\n",
    "        return super()._gen_note(freq = freq, dur = dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "piano=SampleBasedPiano()\n",
    "guitar=SampleBasedGuitar()\n",
    "bass=SampleBasedElectricBass()\n",
    "banjo=SampleBasedBanjo()\n",
    "sax=SampleBasedSaxophone()\n",
    "bassoon=SampleBasedBassoon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
